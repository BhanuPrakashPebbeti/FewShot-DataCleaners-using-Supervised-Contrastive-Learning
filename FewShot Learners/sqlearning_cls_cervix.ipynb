{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pip albumentations==0.4.5 pytorch-lightning\n",
    "!pip install efficientnet-pytorch\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import albumentations as A\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as tvf\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, SequentialSampler\n",
    "from PIL import Image\n",
    "from torch.multiprocessing import cpu_count\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from argparse import Namespace\n",
    "import xml.etree.ElementTree as ET\n",
    "    \n",
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, ...].\n",
    "            labels: ground truth of shape [bsz].\n",
    "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
    "                has the same class as sample i. Can be asymmetric.\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "        \n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "       \n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "     \n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "def random_rotate(image):\n",
    "    if random.random() > 0.5:\n",
    "        return tvf.rotate(image, angle=random.choice((0, 90, 180, 270)))\n",
    "    return image\n",
    "\n",
    "class ResizedRotation():\n",
    "    def __init__(self, angle, output_size=(512,512)):\n",
    "        self.angle = angle\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def angle_to_rad(self, ang): return np.pi * ang / 180.0\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        new_h = int(np.abs(w * np.sin(self.angle_to_rad(90 - self.angle))) + np.abs(h * np.sin(self.angle_to_rad(self.angle))))\n",
    "        new_w = int(np.abs(h * np.sin(self.angle_to_rad(90 - self.angle))) + np.abs(w * np.sin(self.angle_to_rad(self.angle))))\n",
    "        img = tvf.resize(image, (new_w, new_h))\n",
    "        img = tvf.rotate(img, self.angle)\n",
    "        img = tvf.center_crop(img, self.output_size)\n",
    "        return img\n",
    "    \n",
    "class WrapWithRandomParams():\n",
    "    def __init__(self, constructor, ranges):\n",
    "        self.constructor = constructor\n",
    "        self.ranges = ranges\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        randoms = [float(np.random.uniform(low, high)) for _, (low, high) in zip(range(len(self.ranges)), self.ranges)]\n",
    "        return self.constructor(*randoms)(image)\n",
    "    \n",
    "class PretrainingDatasetWrapper(Dataset):\n",
    "    def __init__(self, ds, l, target_size=(512,512), debug=False):\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        self.labels = l\n",
    "        self.debug = debug\n",
    "        self.target_size = target_size\n",
    "        if debug:\n",
    "            print(\"DATASET IN DEBUG MODE\")\n",
    "        \n",
    "        self.preprocess = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        random_resized_rotation = WrapWithRandomParams(lambda angle: ResizedRotation(angle, target_size), [(0.0, 360.0)])\n",
    "        self.randomize = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(target_size, scale=(340/512, 340/512), ratio=(1.0, 1.0)),\n",
    "            transforms.RandomChoice([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Lambda(random_rotate)\n",
    "            ]),\n",
    "            transforms.RandomApply([\n",
    "                random_resized_rotation\n",
    "            ], p=0.6),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(brightness=0.5, contrast=0.6, saturation=0.6, hue=0.3)\n",
    "            ], p=0.8)\n",
    "        ])\n",
    "    \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem_internal__(self, idx, preprocess=True):\n",
    "        this_image_raw_path = self.ds[idx]\n",
    "        label = self.labels[idx]\n",
    "        this_image_raw = Image.open(this_image_raw_path)\n",
    "        if self.debug:\n",
    "            random.seed(idx)\n",
    "            t1 = self.randomize(this_image_raw)\n",
    "            random.seed(idx + 1)\n",
    "            t2 = self.randomize(this_image_raw)\n",
    "        else:\n",
    "            t1 = self.randomize(this_image_raw)\n",
    "            t2 = self.randomize(this_image_raw)\n",
    "        \n",
    "        if preprocess:\n",
    "            t1 = self.preprocess(t1)\n",
    "            t2 = self.preprocess(t2)\n",
    "        else:\n",
    "            t1 = transforms.ToTensor()(t1)\n",
    "            t2 = transforms.ToTensor()(t2)\n",
    "            \n",
    "        return (t1, t2), torch.tensor(label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.__getitem_internal__(idx, True)\n",
    "    \n",
    "    def raw(self, idx):\n",
    "        return self.__getitem_internal__(idx, False)\n",
    "    \n",
    "class ImageEmbedding(nn.Module):       \n",
    "    class Identity(nn.Module):\n",
    "        def __init__(self): super().__init__()\n",
    "\n",
    "        def forward(self, x):\n",
    "            return x\n",
    "    \n",
    "        \n",
    "    def __init__(self, embedding_size=1024):\n",
    "        super().__init__()\n",
    "        base_model = EfficientNet.from_name(\"efficientnet-b2\")\n",
    "        internal_embedding_size = base_model._fc.in_features\n",
    "        base_model._fc = ImageEmbedding.Identity()\n",
    "        \n",
    "        self.embedding = base_model\n",
    "        \n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features=internal_embedding_size, out_features=embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=embedding_size, out_features=embedding_size)\n",
    "        )\n",
    "\n",
    "    def calculate_embedding(self, image):\n",
    "        return self.embedding(image)\n",
    "\n",
    "    def forward(self, X):\n",
    "        image = X\n",
    "        embedding = self.calculate_embedding(image)\n",
    "        projection = self.projection(embedding)\n",
    "        return embedding, projection\n",
    "    \n",
    "hparams = Namespace(\n",
    "    lr=0.001,\n",
    "    epochs=200,\n",
    "    batch_size=51,\n",
    "    train_size=63580,\n",
    "    validation_size=7030\n",
    ")\n",
    "    \n",
    "class ImageEmbeddingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams = hparams):\n",
    "        super().__init__()\n",
    "        self.hparams.update(vars(hparams))\n",
    "        self.model = ImageEmbedding()\n",
    "        self.loss = SupConLoss()\n",
    "    \n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // hparams.epochs\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(PretrainingDatasetWrapper(data,labels,\n",
    "                                             debug=getattr(hparams, \"debug\", False)),\n",
    "                          batch_size=hparams.batch_size, \n",
    "                          num_workers=4,#cpu_count(),\n",
    "                          sampler=SubsetRandomSampler(list(range(hparams.train_size))),\n",
    "                         drop_last=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(PretrainingDatasetWrapper(data,labels,\n",
    "                                            debug=getattr(hparams, \"debug\", False)),\n",
    "                          batch_size=hparams.batch_size, \n",
    "                          shuffle=False,\n",
    "                          num_workers=4,#cpu_count(),\n",
    "                          sampler=SequentialSampler(list(range(hparams.train_size + 1, hparams.train_size + hparams.validation_size))),\n",
    "                         drop_last=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def step(self, batch, step_name = \"train\"):\n",
    "        (X, Y), labels = batch\n",
    "        embX, projectionX = self.forward(X)\n",
    "        embY, projectionY = self.forward(Y)\n",
    "        z_i = F.normalize(projectionX , dim=1)\n",
    "        z_j = F.normalize(projectionY, dim=1)\n",
    "        projX = torch.reshape(z_i,(z_i.shape[0],1,z_i.shape[1]))\n",
    "        projY = torch.reshape(z_j,(z_j.shape[0],1,z_j.shape[1]))\n",
    "        features = torch.cat([projX, projY], dim=1)\n",
    "        loss = self.loss(features=features,labels=labels)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "        self.log(\"loss\" if step_name == \"train\" else loss_key, loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        if len(outputs) == 0:\n",
    "            return {\"val_loss\": torch.tensor(0)}\n",
    "        else:\n",
    "            loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "            return {\"val_loss\": loss, \"log\": {\"val_loss\": loss}}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = RMSprop(self.model.parameters(), lr=hparams.lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=15, verbose=True)\n",
    "        return {\n",
    "           'optimizer': optimizer,\n",
    "           'lr_scheduler': scheduler,\n",
    "           'monitor': 'val_loss'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLRClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, freeze_base, embeddings_model_path, hidden_size=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        base_model = ImageEmbeddingModule.load_from_checkpoint(embeddings_model_path).model\n",
    "        \n",
    "        self.embeddings = base_model.embedding\n",
    "        \n",
    "        if freeze_base:\n",
    "            print(\"Freezing embeddings\")\n",
    "            for param in self.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        # Only linear projection on top of the embeddings should be enough\n",
    "        self.classifier = nn.Sequential(nn.Linear(in_features=base_model.projection[0].in_features,out_features=hidden_size),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.25),                           \n",
    "                      nn.Linear(hidden_size, out_features=n_classes))\n",
    "    \n",
    "    def forward(self, X, *args):\n",
    "        emb = self.embeddings(X)\n",
    "        return self.classifier(emb)\n",
    "    \n",
    "class PretrainingDatasetWrapper_cls(Dataset):\n",
    "    def __init__(self, ds, l, target_size=(512,512), debug=False):\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        self.labels = l\n",
    "        self.debug = debug\n",
    "        self.target_size = target_size\n",
    "        if debug:\n",
    "            print(\"DATASET IN DEBUG MODE\")\n",
    "        \n",
    "        # I will be using network pre-trained on ImageNet first, which uses this normalization.\n",
    "        # Remove this, if you're training from scratch or apply different transformations accordingly\n",
    "        self.preprocess = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        random_resized_rotation = WrapWithRandomParams(lambda angle: ResizedRotation(angle, target_size), [(0.0, 360.0)])\n",
    "        self.randomize = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(target_size, scale=(340/512, 340/512), ratio=(1.0, 1.0)),\n",
    "            transforms.RandomChoice([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Lambda(random_rotate)\n",
    "            ]),\n",
    "            transforms.RandomApply([\n",
    "                random_resized_rotation\n",
    "            ], p=0.6)\n",
    "        ])\n",
    "            \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem_internal__(self, idx, preprocess=True):\n",
    "        this_image_raw_path = self.ds[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(this_image_raw_path)\n",
    "        img = tvf.resize(img, self.target_size)\n",
    "#         img = self.randomize(img)\n",
    "        if preprocess:\n",
    "            t1 = self.preprocess(img)\n",
    "        else:\n",
    "            t1 = transforms.ToTensor()(img)\n",
    "            \n",
    "        return t1, torch.tensor(label).to(torch.float32), this_image_raw_path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.__getitem_internal__(idx, True)\n",
    "    \n",
    "    def raw(self, idx):\n",
    "        return self.__getitem_internal__(idx, False)\n",
    "\n",
    "class SimCLRClassifierModule(pl.LightningModule):\n",
    "    def __init__(self,hparams):\n",
    "        super().__init__()\n",
    "        self.hparams.update(vars(hparams))\n",
    "        self.model = SimCLRClassifier(self.hparams.n_classes, self.hparams.freeze_base, \n",
    "                                      self.hparams.embeddings_path,\n",
    "                                      self.hparams.hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "        \n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.epochs\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        return transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(PretrainingDatasetWrapper_cls(data, labels,\n",
    "                                            debug=getattr(self.hparams, \"debug\", False)),\n",
    "                          batch_size=self.hparams.batch_size, \n",
    "                          shuffle=False,\n",
    "                          num_workers=4,\n",
    "                          sampler=SubsetRandomSampler(list(range(self.hparams.train_size))),\n",
    "                         drop_last=False)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(PretrainingDatasetWrapper_cls(data, labels,\n",
    "                                            debug=getattr(self.hparams, \"debug\", False)),\n",
    "                          batch_size = self.hparams.batch_size, \n",
    "                          shuffle=False,\n",
    "                          num_workers=4,\n",
    "                          sampler=SequentialSampler(list(range(self.hparams.train_size + 1, self.hparams.train_size + self.hparams.validation_size))),\n",
    "                         drop_last=False)\n",
    "    \n",
    "    def test_dataloader(self,dataset):\n",
    "        trash = [0 for i in range(len(dataset))]\n",
    "        return DataLoader(PretrainingDatasetWrapper_cls(dataset, trash,\n",
    "                                            debug=getattr(self.hparams, \"debug\", False)),\n",
    "                          batch_size = 1,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4,\n",
    "                          sampler=SequentialSampler(list(range(len(dataset)))),\n",
    "                         drop_last=False)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        z = self.model(X)\n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    def step(self, batch, step_name = \"train\"):\n",
    "        X, y, _ = batch\n",
    "        y_out = self.forward(X)\n",
    "        loss = self.loss(y_out, y.unsqueeze(1))\n",
    "        y_pred_tag = torch.round(y_out)\n",
    "        y = y.to(torch.int32)\n",
    "        accuracy = self.accuracy(y_pred_tag.squeeze(1), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        accuracy_key = f\"{step_name}_acc\"\n",
    "        tensorboard_logs = {loss_key: loss, accuracy_key: accuracy}\n",
    "        self.log(\"loss\" if step_name == \"train\" else loss_key, loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"acc\" if step_name == \"train\" else accuracy_key, accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        if len(outputs) == 0:\n",
    "            return {\"val_loss\": torch.tensor(0)}\n",
    "        else:\n",
    "            loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "            acc = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "            return {\"val_loss\": loss, \"val_acc\":acc, \"log\": {\"val_loss\": loss,\"val_acc\":acc}}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = RMSprop(self.model.parameters(), lr=self.hparams.lr)\n",
    "        schedulers = [\n",
    "            CosineAnnealingLR(optimizer, self.hparams.epochs)\n",
    "        ] if self.hparams.epochs > 1 else []\n",
    "        return [optimizer], schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Dataset/train_dataset1.csv\")\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imagenet_noise = train_df[train_df[\"id\"] >= 5]\n",
    "train_medical = train_df[train_df[\"id\"] < 5]\n",
    "train_cervix = train_medical[train_medical[\"id\"] == 1]\n",
    "train_medical_noise = train_medical[train_medical[\"id\"] != 1]\n",
    "print(len(train_cervix),len(train_imagenet_noise),len(train_medical_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cervix = train_cervix.sample(n=50, random_state=1)\n",
    "data = list(train_cervix[\"path\"])\n",
    "labels = [0]*len(train_cervix)\n",
    "\n",
    "train_imagenet_noise = train_imagenet_noise.groupby(\"id\").sample(n=1, random_state=1)\n",
    "data.extend(list(train_imagenet_noise[\"path\"]))\n",
    "labels.extend([1]*len(train_imagenet_noise))\n",
    "\n",
    "train_medical_noise = train_medical_noise.groupby(\"id\").sample(n=50, random_state=1)\n",
    "data.extend(list(train_medical_noise[\"path\"]))\n",
    "labels.extend([1]*len(train_medical_noise))\n",
    "\n",
    "print(len(labels),len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(train_cervix.index, axis=0,inplace=True)\n",
    "train_df.drop(train_imagenet_noise.index, axis=0,inplace=True)\n",
    "train_df.drop(train_medical_noise.index, axis=0,inplace=True)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imagenet_noise = train_df[train_df[\"id\"] >= 5]\n",
    "train_medical = train_df[train_df[\"id\"] < 5]\n",
    "train_cervix = train_medical[train_medical[\"id\"] == 1]\n",
    "train_medical_noise = train_medical[train_medical[\"id\"] != 1]\n",
    "print(len(train_cervix),len(train_imagenet_noise),len(train_medical_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cervix = train_cervix.sample(n=1000, random_state=1)\n",
    "data.extend(train_cervix[\"path\"])\n",
    "labels.extend([0]*len(train_cervix))\n",
    "\n",
    "train_imagenet_noise = train_imagenet_noise.groupby(\"id\").sample(n=20, random_state=1)\n",
    "data.extend(list(train_imagenet_noise[\"path\"]))\n",
    "labels.extend([1]*len(train_imagenet_noise))\n",
    "\n",
    "train_medical_noise = train_medical_noise.groupby(\"id\").sample(n=250, random_state=1)\n",
    "data.extend(list(train_medical_noise[\"path\"]))\n",
    "labels.extend([1]*len(train_medical_noise))\n",
    "\n",
    "print(len(labels),len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_cls = Namespace(\n",
    "    lr=1e-3,\n",
    "    epochs=10,\n",
    "    batch_size=20,\n",
    "    n_classes=1,\n",
    "    freeze_base=True,\n",
    "    embeddings_path=\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Checkpoints/model.ckpt\",\n",
    "    hidden_size=512,\n",
    "    train_size=1250,\n",
    "    validation_size=22000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback_cls = ModelCheckpoint(\n",
    "    dirpath=\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Checkpoints_cls\", \n",
    "    filename=\"model\", \n",
    "    monitor='val_loss',\n",
    "    verbose=True, \n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "# early_stop_callback_cls = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=10, verbose=1, mode='min')\n",
    "module_cls = SimCLRClassifierModule(hparams_cls)\n",
    "# trainer_cls = pl.Trainer(gpus=[0],\n",
    "#                          max_epochs=hparams_cls.epochs,\n",
    "#                          callbacks=[checkpoint_callback_cls],#early_stop_callback_cls\n",
    "#                          replace_sampler_ddp = False,\n",
    "#                          progress_bar_refresh_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_cls.fit(module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Checkpoints_cls/model_100_no_aug.ckpt\")\n",
    "module_cls.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_cls = module_cls.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Dataset/Cervical Data.csv\", usecols=range(1,5))\n",
    "df[\"Noise\"].replace({\"0\": 0, \"1\": 1, \"Nan\": 2}, inplace=True)\n",
    "from collections import Counter\n",
    "Counter(list(df[\"Noise\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"Data_type\"] == \"Train\"]\n",
    "# df = df[df[\"Noise\"] == 2]\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# for i in list(df[\"Path\"]):\n",
    "#     img = cv2.imread(i)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def test_evaluate(data_loader, module):\n",
    "    with torch.no_grad():\n",
    "        module.eval().cuda()\n",
    "        pred_y = []\n",
    "        images = []\n",
    "        for batch_ in tqdm(data_loader):\n",
    "            X, y, path = batch_\n",
    "            result = module(X.cuda())\n",
    "            y_pred = torch.round(result)\n",
    "            if int(y_pred[0][0]) == 1:\n",
    "                images.append(path)\n",
    "            pred_y.extend(y_pred.cpu())\n",
    "        return pred_y, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred , noise_images = test_evaluate(module_cls.test_dataloader(list(test_data[\"Path\"])), module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "test_pred = [int(o) for o in test_pred]\n",
    "frequency = collections.Counter(np.array(test_pred))\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Predicted_label\"] = list(test_pred)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labelled = test_data[test_data[\"Noise\"] != 2]\n",
    "noise_predicted_total = test_data[test_data[\"Predicted_label\"] == 1]\n",
    "noise_predicted_manual = manual_labelled[manual_labelled [\"Predicted_label\"] == 1]\n",
    "wrong = noise_predicted_manual[noise_predicted_manual[\"Noise\"] == 0]\n",
    "train = wrong[wrong[\"Data_type\"] == \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of test data :\", len(test_data))\n",
    "print(\"Length of data having manual labels in test data :\", len(manual_labelled))\n",
    "print(\"Length of data predicted as noise in total test data :\", len(noise_predicted_total))\n",
    "print(\"Length of data predicted as noise in manual available data :\", len(noise_predicted_manual))\n",
    "print(\"Number of cervix labelled manually predicted as noise :\", len(wrong))\n",
    "print(\"Number of train cervical data predicted as noise :\", len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Classifier/100_no_aug/Dataset_100_no_aug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for h in range(10):\n",
    "    fig,ax = plt.subplots(10,6,figsize=(60,100))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(10):\n",
    "        for j in range(6):\n",
    "            try:\n",
    "                path = list(noise_predicted_total[\"Path\"])[k]\n",
    "                a = path.split(\"/\")\n",
    "                txt_x = \"Label:\"+str(noise_predicted_total.iloc[k][\"Noise\"])+\" \"+\"Predict:\"+str(noise_predicted_total.iloc[k][\"Predicted_label\"])\n",
    "                txt_y = str(a[-1])+\"  Data :\"+str(noise_predicted_total.iloc[k][\"Data_type\"])\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                ax[i][j].imshow(img)\n",
    "                ax[i][j].set_xticks([])\n",
    "                ax[i][j].set_yticks([])\n",
    "                ax[i][j].set_xlabel(str(txt_x),color=\"black\",fontsize=35)\n",
    "                ax[i][j].set_ylabel(str(txt_y),color=\"black\",fontsize=35)\n",
    "            except:\n",
    "                dummy = np.zeros((512,512,3),np.uint8)\n",
    "                ax[i][j].imshow(dummy)\n",
    "                ax[i][j].axis('off')\n",
    "            k+= 1\n",
    "    fig.savefig(\"Predictions_1250_noaug_freezed_{}.png\".format(h))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for h in range(7):\n",
    "    fig,ax = plt.subplots(10,6,figsize=(60,100))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(10):\n",
    "        for j in range(6):\n",
    "            try:\n",
    "                path = list(wrong[\"Path\"])[k]\n",
    "                a = path.split(\"/\")\n",
    "                txt_x = \"Label:\"+str(wrong.iloc[k][\"Noise\"])+\" \"+\"Predict:\"+str(wrong.iloc[k][\"Predicted_label\"])\n",
    "                txt_y = str(a[-1])+\"  Data :\"+str(wrong.iloc[k][\"Data_type\"])\n",
    "                img = cv2.imread(path)\n",
    "                ax[i][j].imshow(img)\n",
    "                ax[i][j].set_xticks([])\n",
    "                ax[i][j].set_yticks([])\n",
    "                ax[i][j].set_xlabel(str(txt_x),color=\"black\",fontsize=35)\n",
    "                ax[i][j].set_ylabel(str(txt_y),color=\"black\",fontsize=35)\n",
    "            except:\n",
    "                dummy = np.zeros((512,512,3),np.uint8)\n",
    "                ax[i][j].imshow(dummy)\n",
    "                ax[i][j].axis('off')\n",
    "            k+= 1\n",
    "    fig.savefig(\"SC_binary_v1_trainedv2data_noise_{}.png\".format(h))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"/workstation/home/bijoy/data_from_b170007ec/Programs/Bhanu/SCLEARNING/Output_csv/Model_binary_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.listdir(\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Imagenet/.kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Imagenet/\n",
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_ext = pd.read_csv(\"/workstation/home/bijoy/data_from_b170007ec/Programs/Bhanu/SCLEARNING/TESTING_ON_5DATASETS/testing_data.csv\")\n",
    "test_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_ext))\n",
    "imagenetdata = test_ext[test_ext[\"imagenet\"] == 1]\n",
    "print(len(imagenetdata))\n",
    "blooddata = test_ext[test_ext[\"blood\"] == 1]\n",
    "print(len(blooddata))\n",
    "eyedata = test_ext[test_ext[\"eye\"] == 1]\n",
    "print(len(eyedata))\n",
    "skindata = test_ext[test_ext[\"skin\"] == 1]\n",
    "print(len(skindata))\n",
    "surgerydata = test_ext[test_ext[\"surgery\"] == 1]\n",
    "print(len(surgerydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred , noise_images = test_evaluate(module_cls.test_dataloader(list(imagenetdata[\"Path\"])), module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "test_pred = [int(o) for o in test_pred]\n",
    "frequency = collections.Counter(np.array(test_pred))\n",
    "frequency = dict(frequency)\n",
    "print(frequency)\n",
    "if len(frequency) == 1:\n",
    "    try:\n",
    "        print(\"Percentage of Imagenet data retrived from dataset : \", (frequency[1]*100/frequency[1]),\"%\")\n",
    "    except:\n",
    "        print(\"Percentage of Imagenet data retrived from dataset : \", (frequency[0]*100/frequency[0]),\"%\")\n",
    "else:\n",
    "    print(\"Percentage of Imagenet data retrived from dataset : \", (frequency[1]*100/(frequency[0]+frequency[1])),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred , noise_images = test_evaluate(module_cls.test_dataloader(list(blooddata[\"Path\"])), module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "test_pred = [int(o) for o in test_pred]\n",
    "frequency = collections.Counter(np.array(test_pred))\n",
    "frequency = dict(frequency)\n",
    "print(frequency)\n",
    "if len(frequency) == 1:\n",
    "    try:\n",
    "        print(\"Percentage of blood data retrived from dataset : \", (frequency[1]*100/frequency[1]),\"%\")\n",
    "    except:\n",
    "        print(\"Percentage of blood data retrived from dataset : \", (frequency[0]*100/frequency[0]),\"%\")\n",
    "else:\n",
    "    print(\"Percentage of blood data retrived from dataset : \", (frequency[1]*100/(frequency[0]+frequency[1])),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred , noise_images = test_evaluate(module_cls.test_dataloader(list(eyedata[\"Path\"])), module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "test_pred = [int(o) for o in test_pred]\n",
    "frequency = collections.Counter(np.array(test_pred))\n",
    "frequency = dict(frequency)\n",
    "print(frequency)\n",
    "if len(frequency) == 1:\n",
    "    try:\n",
    "        print(\"Percentage of eye data retrived from dataset : \", (frequency[1]*100/frequency[1]),\"%\")\n",
    "    except:\n",
    "        print(\"Percentage of eye data retrived from dataset : \", (frequency[0]*100/frequency[0]),\"%\")\n",
    "else:\n",
    "    print(\"Percentage of eye data retrived from dataset : \", (frequency[1]*100/(frequency[0]+frequency[1])),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred , noise_images = test_evaluate(module_cls.test_dataloader(list(skindata[\"Path\"])), module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "test_pred = [int(o) for o in test_pred]\n",
    "frequency = collections.Counter(np.array(test_pred))\n",
    "frequency = dict(frequency)\n",
    "print(frequency)\n",
    "if len(frequency) == 1:\n",
    "    try:\n",
    "        print(\"Percentage of skin data retrived from dataset : \", (frequency[1]*100/frequency[1]),\"%\")\n",
    "    except:\n",
    "        print(\"Percentage of skin data retrived from dataset : \", (frequency[0]*100/frequency[0]),\"%\")\n",
    "else:\n",
    "    print(\"Percentage of skin data retrived from dataset : \", (frequency[1]*100/(frequency[0]+frequency[1])),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred , noise_images = test_evaluate(module_cls.test_dataloader(list(surgerydata[\"Path\"])), module_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "test_pred = [int(o) for o in test_pred]\n",
    "frequency = collections.Counter(np.array(test_pred))\n",
    "frequency = dict(frequency)\n",
    "print(frequency)\n",
    "if len(frequency) == 1:\n",
    "    try:\n",
    "        print(\"Percentage of surgery data retrived from dataset : \", (frequency[1]*100/frequency[1]),\"%\")\n",
    "    except:\n",
    "        print(\"Percentage of surgery data retrived from dataset : \", (frequency[0]*100/frequency[0]),\"%\")\n",
    "else:\n",
    "    print(\"Percentage of surgery data retrived from dataset : \", (frequency[1]*100/(frequency[0]+frequency[1])),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"/workstation/home/bijoy/data_from_b170007ec/Datasets/Cervix Cancer/train/additional_Type_2_v2/4283.jpg\"\n",
    "h = path.split(\"/\")\n",
    "y_txt = \"{} Data: {}\".format(h[-1],h[-2].split(\"_\")[0])\n",
    "img = cv2.imread(path)\n",
    "plt.imshow(img)\n",
    "plt.ylabel(str(y_txt),color=\"black\",fontsize=15)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig(\"f.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/workstation/raid/home/p170059cs/data_from_b170007ec/Programs/Bhanu/CERVICAL2.0/Classifier/Cervix/100_aug/Dataset_100_aug.csv\")\n",
    "df = df[df[\"Predicted_label\"] == 1]\n",
    "paths = list(df[\"Path\"])\n",
    "for i in range(len(paths)):\n",
    "    path = paths[i].replace(\"/workstation/raid/home/p170059cs/bijoy_backup/data_from_b170007ec\",\"/workstation/raid/home/p170059cs/data_from_b170007ec\")\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
